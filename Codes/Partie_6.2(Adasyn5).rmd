---
title: "ADASYN5"
author: "Laffineur Loïc"
date: "`r Sys.Date()`"
output: html_document
---

```{r library, include=FALSE}
#Manipulation : 
library(dplyr)

#Modèles de ML :
library(randomForest) #RF ;
library(rpart) #CART ;
library(xgboost) #XGBoost ;
library(glmnet)
library(class)
library(naivebayes)
library(ranger)
library(kernlab)
library(e1071) #Algo de ML

#Autres pour ML :
library(caret) #Split/Search/... ;
library(caretEnsemble)

library(MLmetrics) #Metriques d'évaluation
library(ROSE)

library(smotefamily)#ADAS
```

```{r, mat_model_names}
load("intro_data.RData")
rm(tab_ML)
model_names=c("Regression logistique","K_NN","Naive Bayes","SVM RBF","SVM Polynomial","CART","Ranger","RandomForest","XGBoost")
```

# Création de la table : 

```{r, adasyn}
#Modification des données pour adasyn 
data_train$nb_phies=as.numeric(data_train$nb_phies)
data_train$active_tout2018_1=as.numeric(data_train$active_tout2018_1)-1
data_train$top_sanction=as.factor(make.names(data_train$top_sanction))

X_test$active_tout2018_1=as.numeric(X_test$active_tout2018_1)-1

acp_train$top_sanction=as.factor(make.names(acp_train$top_sanction))

#Package adasynfamily
set.seed(12)
adasyn_=ADAS(data_train[,-ncol(data_train)],data_train$top_sanction,K=5)
colnames(adasyn_$syn_data)[ncol(adasyn_$syn_data)]="top_sanction"

set.seed(12)
k=sample(nrow(adasyn_$syn_data), 
         size = as.numeric(table(data_train$top_sanction)[2]-table(data_train$top_sanction)[1]))
adasyn_train5=rbind(data_train,adasyn_$syn_data[k,])

table(adasyn_train5$top_sanction)
rm(k)

#ACP
set.seed(12)
adasyn_=ADAS(acp_train[,-ncol(acp_train)],acp_train$top_sanction,K=5)
colnames(adasyn_$syn_data)[ncol(adasyn_$syn_data)]="top_sanction"

set.seed(12)
k=sample(nrow(adasyn_$syn_data), 
         size = as.numeric(table(acp_train$top_sanction)[2]-table(acp_train$top_sanction)[1]))
adasyn_acp5=rbind(acp_train,adasyn_$syn_data[k,])

rm(k,adasyn_)
```

```{r, procedure pour CV}
adasyn_train5$nb_phies=as.numeric(adasyn_train5$nb_phies)
adasyn_train5$active_tout2018_1=as.numeric(adasyn_train5$active_tout2018_1)-1
adasyn_train5$top_sanction=as.factor(make.names(adasyn_train5$top_sanction))

adasyn_acp5$top_sanction=as.factor(make.names(adasyn_acp5$top_sanction))

X_test$active_tout2018_1=as.numeric(X_test$active_tout2018_1)-1
y_test=as.factor(make.names(y_test))

#Création de la base de donnée en bonne forme : 
#Train : 
x_adasyn=data.matrix(adasyn_train5[,-ncol(adasyn_train5)])
x_adasyn_acp=data.matrix(adasyn_acp5[,-ncol(adasyn_acp5)])

#Test : 
test_data=data.matrix(X_test); test_data[,1]=test_data[,1]-1
test_acp=data.matrix(acp_test)

#Nos folds pour la CV :
set.seed(12)
folds_data=createFolds(adasyn_train5$top_sanction,k=5)
folds_acp=createFolds(adasyn_acp5$top_sanction,k=5)

#Règle de CV : 
Control_data <- trainControl(method = "cv", number = 5, index=folds_data, search='random',
                           classProbs = T, #Pour mes metrics AUC Sensi et Spé
                           summaryFunction = twoClassSummary, verboseIter = F)

Control_acp <- trainControl(method = "cv", number = 5, index=folds_acp, search='random',
                           classProbs = T, #Pour mes metrics AUC Sensi et Spé
                           summaryFunction = twoClassSummary, verboseIter = F)
```

```{r, entrainement des modèles avec CV,warning=F}
set.seed(12)
#Liste des modèles :
start_time=Sys.time()
model_list_adasyn5 <- caretList(trControl = Control_data, 
                        tuneList = list(
                          glm=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="glmnet", tuneLength=300,
                                             metric="ROC"),
                          knn=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction, 
                                             method="knn", tuneLength=300,
                                             metric="ROC"), 
                          naive_bayes=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="naive_bayes", tuneLength=300,
                                             metric="ROC"),
                          svm_rad=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="svmRadial", tuneLength=300,
                                             metric="ROC"),
                          svm_poly=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="svmPoly", tuneLength=300,
                                             metric="ROC"),
                          rpart=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="rpart2", tuneLength=300,
                                             metric="ROC"),
                          ranger=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="ranger", tuneLength=500,
                                             metric="ROC",verbose=F),
                          rf=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="rf", tuneLength=500,
                                             metric="ROC"),
                          xgbTree=caretModelSpec(x=x_adasyn, y=adasyn_train5$top_sanction,
                                             method="xgbTree", tuneLength=500,
                                             metric="ROC",verbosity=0)
                          ),
                        continue_on_fail = FALSE, preProcess = c("center", "scale","nzv"))
end_time=Sys.time()
end_time-start_time #Time difference of 52.02144 mins


#Liste des modèles :
set.seed(12)
start_time=Sys.time()
model_list_adasyn_acp5 <- caretList(trControl = Control_acp, 
                        tuneList = list(
                          glm=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="glmnet", tuneLength=300,
                                             metric="ROC"),
                          knn=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="knn", tuneLength=300,
                                             metric="ROC"), 
                          naive_bayes=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="naive_bayes", tuneLength=300,
                                             metric="ROC"),
                          svm_rad=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="svmRadial", tuneLength=300,
                                             metric="ROC"),
                          svm_poly=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="svmPoly", tuneLength=300,
                                             metric="ROC"),
                          rpart=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="rpart2", tuneLength=300,
                                             metric="ROC"),
                          ranger=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="ranger", tuneLength=500,
                                             metric="ROC",verbose=F),
                          rf=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="rf", tuneLength=500,
                                             metric="ROC"),
                          xgbTree=caretModelSpec(x=x_adasyn_acp, y=adasyn_acp5$top_sanction,
                                             method="xgbTree", tuneLength=500,
                                             metric="ROC")
                          ),
                        continue_on_fail = FALSE, preProcess = c("center", "scale","nzv"))
end_time=Sys.time()
end_time-start_time #Time difference of 42.80208 mins

rm(end_time,start_time)
```

# Régression Logistique :

```{r}
Erreur(predict(model_list_adasyn5$glm,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$glm,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$glm,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$glm,test_acp),y_test)
```

Underfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$glm,x_adasyn),col=col[1],main="ROC Curve régression logistique")
roc.curve(y_test,predict(model_list_adasyn5$glm,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$glm,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$glm,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r}
### Importance des variables : 
barplot(as.matrix(varImp(model_list_adasyn5$glm)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")
barplot(as.matrix(varImp(model_list_adasyn_acp5$glm)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# k-NN :

```{r}
Erreur(predict(model_list_adasyn5$knn,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$knn,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$knn,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$knn,test_acp),y_test)
```

Underfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$knn,x_adasyn),col=col[1],main="ROC Curve k-NN")
roc.curve(y_test,predict(model_list_adasyn5$knn,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$knn,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$knn,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
# Importance des variables :
barplot(as.matrix(varImp(model_list_adasyn5$knn)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")

barplot(as.matrix(varImp(model_list_adasyn_acp5$knn)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# Naive Bayes :

```{r}
Erreur(predict(model_list_adasyn5$naive_bayes,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$naive_bayes,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$naive_bayes,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$naive_bayes,test_acp),y_test)
```

Underfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$naive_bayes,x_adasyn),col=col[1],main="ROC Curve Naive Bayes")
roc.curve(y_test,predict(model_list_adasyn5$naive_bayes,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$naive_bayes,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$naive_bayes,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
#Importance des variables
barplot(as.matrix(varImp(model_list_adasyn5$naive_bayes)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")
barplot(as.matrix(varImp(model_list_adasyn_acp5$naive_bayes)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# SVM : 

## RBF : 

```{r}
Erreur(predict(model_list_adasyn5$svm_rad,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$svm_rad,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$svm_rad,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$svm_rad,test_acp),y_test)
```

Overfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$svm_rad,x_adasyn),col=col[1],main="ROC Curve SVM avec noyau RBF")
roc.curve(y_test,predict(model_list_adasyn5$svm_rad,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$svm_rad,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$svm_rad,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
#Importance des variables
barplot(as.matrix(varImp(model_list_adasyn5$svm_rad)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")

barplot(as.matrix(varImp(model_list_adasyn_acp5$svm_rad)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

## Polynomial : 

```{r}
Erreur(predict(model_list_adasyn5$svm_poly,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$svm_poly,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$svm_poly,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$svm_poly,test_acp),y_test)
```

Underfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$svm_poly,x_adasyn),col=col[1],main="ROC Curve SVM avec noyau Polynomial")
roc.curve(y_test,predict(model_list_adasyn5$svm_poly,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$svm_poly,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$svm_poly,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
#Importance des variables
barplot(as.matrix(varImp(model_list_adasyn5$svm_poly)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")
barplot(as.matrix(varImp(model_list_adasyn_acp5$svm_poly)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# Decision Tree :

```{r}
Erreur(predict(model_list_adasyn5$rpart,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$rpart,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$rpart,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$rpart,test_acp),y_test)
```

Overfitting et underfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$rpart,x_adasyn),col=col[1],main="ROC Curve CART")
roc.curve(y_test,predict(model_list_adasyn5$rpart,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$rpart,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$rpart,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, plot_tree, fig.height=8}
plot(model_list_adasyn5$rpart$finalModel,uniform=T)
text(model_list_adasyn5$rpart$finalModel)

plot(model_list_adasyn_acp5$rpart$finalModel,uniform=T)
text(model_list_adasyn_acp5$rpart$finalModel)
```

```{r, importance_tree}
barplot(as.matrix(varImp(model_list_adasyn5$rpart)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")

barplot(as.matrix(varImp(model_list_adasyn_acp5$rpart)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# Random Forest : 

## randomForest : 

```{r}
Erreur(predict(model_list_adasyn5$rf,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$rf,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$rf,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$rf,test_acp),y_test)
```

Overfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$rf,x_adasyn),col=col[1],main="ROC Curve avec randomForest")
roc.curve(y_test,predict(model_list_adasyn5$rf,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$rf,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$rf,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
#Importance des variables
barplot(as.matrix(varImp(model_list_adasyn5$rf)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")

barplot(as.matrix(varImp(model_list_adasyn_acp5$rf)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

## Ranger : 

```{r}
Erreur(predict(model_list_adasyn5$ranger,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$ranger,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$ranger,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$ranger,test_acp),y_test)
```

Overfitting

```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$ranger,x_adasyn),col=col[1],main="ROC Curve avec Ranger")
roc.curve(y_test,predict(model_list_adasyn5$ranger,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$ranger,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$ranger,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
# #Importance des variables
# barplot(as.matrix(varImp(model_list_adasyn5$ranger)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")
# 
# barplot(as.matrix(varImp(model_list_adasyn_acp5$ranger)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# XGBoost :

```{r}
Erreur(predict(model_list_adasyn5$xgbTree,x_adasyn),adasyn_train5$top_sanction)
Erreur(predict(model_list_adasyn5$xgbTree,test_data),y_test)
Erreur(predict(model_list_adasyn_acp5$xgbTree,x_adasyn_acp),adasyn_acp5$top_sanction)
Erreur(predict(model_list_adasyn_acp5$xgbTree,test_acp),y_test)
```

Overfitting mais bons résutlats sur le test sur la table sans acp ! 


```{r, etude des résultats}
col=rainbow(4)
roc.curve(adasyn_train5$top_sanction,predict(model_list_adasyn5$xgbTree,x_adasyn),col=col[1],main="ROC Curve XGBoost")
roc.curve(y_test,predict(model_list_adasyn5$xgbTree,test_data),add.roc = T,col=col[2])
roc.curve(adasyn_acp5$top_sanction,predict(model_list_adasyn_acp5$xgbTree,x_adasyn_acp),add.roc = T,col=col[3])
roc.curve(y_test,predict(model_list_adasyn_acp5$xgbTree,test_acp),add.roc = T,col=col[4])
legend('bottomright',legend=c("Train sans ACP","Test sans ACP","Train avec ACP","Test avec ACP"),lwd=2,col=col)
rm(col)
```

```{r, importance}
#Importance des variables
barplot(as.matrix(varImp(model_list_adasyn5$xgbTree)$importance)[,1],las=2,col=rainbow(ncol(adasyn_train5)),main="Importance des variables (Sans ACP)")
barplot(as.matrix(varImp(model_list_adasyn_acp5$xgbTree)$importance)[,1],las=2,col=rainbow(ncol(adasyn_acp5)),main="Importance des variables (Avec ACP)")
```

# Comparaison des modèles optimisés entre eux : 

```{r, prediction sur le test}
print("Sans ACP : ")
print(model_names[1])
Erreur(predict(model_list_adasyn5$glm,test_data),y_test)
print(model_names[2])
Erreur(predict(model_list_adasyn5$knn,test_data),y_test)
print(model_names[3])
Erreur(predict(model_list_adasyn5$naive_bayes,test_data),y_test)
print(model_names[4])
Erreur(predict(model_list_adasyn5$svm_rad,test_data),y_test)
print(model_names[5])
Erreur(predict(model_list_adasyn5$svm_poly,test_data),y_test)
print(model_names[6])
Erreur(predict(model_list_adasyn5$rpart,test_data),y_test)
print(model_names[7])
Erreur(predict(model_list_adasyn5$ranger,test_data),y_test)
print(model_names[8])
Erreur(predict(model_list_adasyn5$rf,test_data),y_test)
print(model_names[9])
Erreur(predict(model_list_adasyn5$xgbTree,test_data),y_test)

col=rainbow(9)
roc.curve(y_test,predict(model_list_adasyn5$glm,test_data),col=col[1],main="ROC Curve")
roc.curve(y_test,predict(model_list_adasyn5$knn,test_data),col=col[2],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$naive_bayes,test_data),col=col[3],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$svm_rad,test_data),col=col[4],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$svm_poly,test_data),col=col[5],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$rpart,test_data),col=col[6],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$ranger,test_data),col=col[7],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$rf,test_data),col=col[8],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn5$xgbTree,test_data),col=col[9],add.roc = T)
legend('bottomright',legend=model_names,col=col,lwd=2)

for(i in 1:5){print("")}

print("ACP : ")
print(model_names[1])
Erreur(predict(model_list_adasyn_acp5$glm,test_acp),y_test)
print(model_names[2])
Erreur(predict(model_list_adasyn_acp5$knn,test_acp),y_test)
print(model_names[3])
Erreur(predict(model_list_adasyn_acp5$naive_bayes,test_acp),y_test)
print(model_names[4])
Erreur(predict(model_list_adasyn_acp5$svm_rad,test_acp),y_test)
print(model_names[5])
Erreur(predict(model_list_adasyn_acp5$svm_poly,test_acp),y_test)
print(model_names[6])
Erreur(predict(model_list_adasyn_acp5$rpart,test_acp),y_test)
print(model_names[7])
Erreur(predict(model_list_adasyn_acp5$ranger,test_acp),y_test)
print(model_names[8])
Erreur(predict(model_list_adasyn_acp5$rf,test_acp),y_test)
print(model_names[9])
Erreur(predict(model_list_adasyn_acp5$xgbTree,test_acp),y_test)

roc.curve(y_test,predict(model_list_adasyn_acp5$glm,test_acp),col=col[1],main="ROC Curve avec ACP")
roc.curve(y_test,predict(model_list_adasyn_acp5$knn,test_acp),col=col[2],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$naive_bayes,test_acp),col=col[3],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$svm_rad,test_acp),col=col[4],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$svm_poly,test_acp),col=col[5],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$rpart,test_acp),col=col[6],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$ranger,test_acp),col=col[7],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$rf,test_acp),col=col[8],add.roc = T)
roc.curve(y_test,predict(model_list_adasyn_acp5$xgbTree,test_acp),col=col[9],add.roc = T)
legend('bottomright',legend=model_names,col=col,lwd=2)

rm(col,i)
```
